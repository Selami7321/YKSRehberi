{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpuSMywFU4F2CxKclZ6rNZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Selami7321/YKSRehberi/blob/main/YKSREHBER%C4%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgMHCPxlJn7C",
        "outputId": "3d13c18e-8afd-4dc6-98e8-98fc1eb1366f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š YKS Ã–NEM PUANLARI TABLOSU\n",
            "================================================================================\n",
            "                                                    Konu  Ortalama_Onem_Puani  \\\n",
            "Paragrafta Konu -AnadÃ¼Å£Ã¼nce  Paragrafta Konu -AnadÃ¼Å£Ã¼nce                 15.0   \n",
            "Paragrafta Yardimci Dusunce  Paragrafta Yardimci Dusunce                 12.8   \n",
            "Paragrafta Yapi                          Paragrafta Yapi                 12.4   \n",
            "Fonksiyonlar                                Fonksiyonlar                 10.8   \n",
            "Paragrafin Yapisi                      Paragrafin Yapisi                 10.4   \n",
            "Elektrik                                        Elektrik                  9.6   \n",
            "Atom ve Periyodik Sistem        Atom ve Periyodik Sistem                  9.6   \n",
            "Mutlak Deger                                Mutlak Deger                  9.6   \n",
            "Temel Kavramlar                          Temel Kavramlar                  9.6   \n",
            "Hareket ve Kuvvet                      Hareket ve Kuvvet                  9.6   \n",
            "\n",
            "                             Trend  Standart_Sapma  Min_Puan  Max_Puan  \\\n",
            "Paragrafta Konu -AnadÃ¼Å£Ã¼nce      0        0.707107        14        16   \n",
            "Paragrafta Yardimci Dusunce      2        0.836660        12        14   \n",
            "Paragrafta Yapi                  1        0.547723        12        13   \n",
            "Fonksiyonlar                     2        0.836660        10        12   \n",
            "Paragrafin Yapisi                0        0.547723        10        11   \n",
            "Elektrik                         0        0.547723         9        10   \n",
            "Atom ve Periyodik Sistem         1        0.547723         9        10   \n",
            "Mutlak Deger                     1        0.547723         9        10   \n",
            "Temel Kavramlar                  1        0.547723         9        10   \n",
            "Hareket ve Kuvvet                1        0.547723         9        10   \n",
            "\n",
            "                            Onem_Seviyesi  \n",
            "Paragrafta Konu -AnadÃ¼Å£Ã¼nce        Kritik  \n",
            "Paragrafta Yardimci Dusunce        Kritik  \n",
            "Paragrafta Yapi                    Kritik  \n",
            "Fonksiyonlar                       Kritik  \n",
            "Paragrafin Yapisi                  Kritik  \n",
            "Elektrik                           Kritik  \n",
            "Atom ve Periyodik Sistem           Kritik  \n",
            "Mutlak Deger                       Kritik  \n",
            "Temel Kavramlar                    Kritik  \n",
            "Hareket ve Kuvvet                  Kritik  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Ã–rnek YKS Ã¶nem puanÄ± verisi oluÅŸturma (2020-2024)\n",
        "def create_yks_importance_data():\n",
        "    years = [2020, 2021, 2022, 2023, 2024]\n",
        "\n",
        "    importance_data = {\n",
        "        # TÃ¼rkÃ§e KonularÄ±\n",
        "        'Sozcukte Anlam': [8, 8, 7, 8, 8],\n",
        "        'Soz Yorumu': [6, 7, 7, 6, 7],\n",
        "        'Paragrafta Yapi': [12, 12, 13, 12, 13],\n",
        "        'Paragrafta Konu -AnadÃ¼Å£Ã¼nce': [15, 14, 15, 16, 15],\n",
        "        'Paragrafta Yardimci Dusunce': [12, 13, 12, 13, 14],\n",
        "        'Paragrafta Anlatim Teknikleri': [8, 7, 8, 7, 8],\n",
        "        'Paragrafta Dusunce': [9, 8, 9, 8, 9],\n",
        "        'Paragrafin Yapisi': [10, 11, 10, 11, 10],\n",
        "        'Paragrafta Kisi Ozellikleri': [7, 6, 7, 6, 7],\n",
        "        'Paragrafi Parcalara Bolerek Anlama': [5, 6, 5, 6, 5],\n",
        "        'Deyim ve AtasÃ¶zÃ¼': [6, 5, 6, 5, 6],\n",
        "        'Ek Fiil': [4, 5, 4, 5, 4],\n",
        "        'Fiilimsi': [7, 6, 7, 6, 7],\n",
        "        'Ses Bilgisi': [5, 4, 5, 4, 5],\n",
        "\n",
        "        # Matematik KonularÄ±\n",
        "        'Temel Kavramlar': [9, 10, 9, 10, 10],\n",
        "        'Bolme ve Bolunebilme': [6, 7, 6, 7, 6],\n",
        "        'Birinci Dereceden Denklemler': [8, 8, 9, 8, 9],\n",
        "        'EBOB-EKOK': [5, 6, 5, 6, 5],\n",
        "        'Oran-Oranti': [7, 8, 7, 8, 8],\n",
        "        'Koklu Sayilar': [8, 7, 8, 7, 8],\n",
        "        'Uslu Sayilar': [8, 9, 8, 9, 8],\n",
        "        'Mutlak Deger': [9, 10, 9, 10, 10],\n",
        "        'Karisim Problemleri': [6, 7, 6, 7, 6],\n",
        "        'Sayi ve Kesir Problemleri': [7, 8, 7, 8, 8],\n",
        "        'Isci Problemleri': [4, 5, 4, 5, 4],\n",
        "        'Hareket Problemleri': [5, 6, 5, 6, 5],\n",
        "        'Yas Problemleri': [4, 5, 4, 5, 4],\n",
        "        'Oran-Oranti Problemleri': [6, 7, 6, 7, 7],\n",
        "        'Kar-Zarar Problemleri': [5, 6, 5, 6, 5],\n",
        "        'Carpanlara Ayirma': [8, 9, 8, 9, 9],\n",
        "        'Denklem Cozme': [7, 8, 7, 8, 8],\n",
        "        'Kumeler-Kartezyen Ã‡arpimi': [6, 7, 6, 7, 6],\n",
        "        'Fonksiyonlar': [10, 11, 10, 11, 12],\n",
        "        'Veri-Ãstatistik': [7, 8, 7, 8, 7],\n",
        "        'Rasyonel Sayilar': [8, 7, 8, 7, 8],\n",
        "        'Ikinci Dereceden Denklemler': [9, 8, 9, 8, 9],\n",
        "        'Permutasyon ve Kombinasyon': [8, 9, 8, 9, 9],\n",
        "\n",
        "        # Geometri KonularÄ±\n",
        "        'Dogruda Acilar': [6, 7, 6, 7, 6],\n",
        "        'Ucgende Acilar': [7, 8, 7, 8, 8],\n",
        "        'Dik Ãœcgen': [8, 7, 8, 7, 8],\n",
        "        'Ozel Ucgenler': [7, 8, 7, 8, 7],\n",
        "        'Ikizkenar Ucgen': [6, 7, 6, 7, 6],\n",
        "        'Eskenar Ucgen': [5, 6, 5, 6, 5],\n",
        "\n",
        "        # Fizik KonularÄ±\n",
        "        'Madde ve Ozellikleri': [8, 9, 8, 9, 9],\n",
        "        'Fizik Bilimine Giris': [7, 6, 7, 6, 7],\n",
        "        'BasÃ½nc': [8, 7, 8, 7, 8],\n",
        "        'Hareket ve Kuvvet': [9, 10, 9, 10, 10],\n",
        "        'Sivilarin KaldÃ½rma Kuvveti': [7, 8, 7, 8, 7],\n",
        "        'Isi,Sicaklik ve Genlesme': [8, 7, 8, 7, 8],\n",
        "        'Dinamik': [9, 10, 9, 10, 10],\n",
        "        'Is,Guc ve Enerji': [8, 9, 8, 9, 8],\n",
        "        'Elektrik': [10, 9, 10, 9, 10],\n",
        "        'Dalgalar': [8, 7, 8, 7, 8],\n",
        "\n",
        "        # Kimya KonularÄ±\n",
        "        'Doga ve Kimya': [6, 7, 6, 7, 6],\n",
        "        'Atom ve Periyodik Sistem': [9, 10, 9, 10, 10],\n",
        "        'Maddenin Halleri': [8, 7, 8, 7, 8],\n",
        "        'Kimyasal Turler Arasi Etkilesimler': [7, 8, 7, 8, 7],\n",
        "\n",
        "        # Biyoloji KonularÄ±\n",
        "        'Canlilarin Ortak Ozellikleri': [7, 8, 7, 8, 7],\n",
        "        'Canlilarin Temel Bilesenleri': [8, 9, 8, 9, 9],\n",
        "        'Hucre ve Organelleri': [9, 8, 9, 8, 9],\n",
        "        'Hucre ZarÃ½ndan Madde Gecisi': [7, 8, 7, 8, 7],\n",
        "        'Canlilarin Siniflandirilmasi': [6, 7, 6, 7, 6],\n",
        "        'Mitoz ve Eseysiz Ureme': [8, 7, 8, 7, 8],\n",
        "        'Mayoz ve Eseyli Ureme': [9, 10, 9, 10, 10],\n",
        "        'Kalitim': [10, 9, 10, 9, 10],\n",
        "        'Ekosistem Ekolojisi': [6, 7, 6, 7, 6],\n",
        "        'Guncel Cevre Sorunlari': [7, 8, 7, 8, 8]\n",
        "    }\n",
        "\n",
        "    return pd.DataFrame(importance_data, index=years)\n",
        "\n",
        "# Ã–nem puanlarÄ±nÄ± hesapla\n",
        "yks_importance_df = create_yks_importance_data()\n",
        "\n",
        "# Ortalama Ã¶nem puanlarÄ±nÄ± hesapla ve 0-100 Ã¶lÃ§eÄŸine normalize et\n",
        "importance_summary = pd.DataFrame({\n",
        "    'Konu': yks_importance_df.columns,\n",
        "    'Ortalama_Onem_Puani': yks_importance_df.mean(),\n",
        "    'Trend': yks_importance_df.iloc[-1] - yks_importance_df.iloc[0],  # Son yÄ±l - Ä°lk yÄ±l\n",
        "    'Standart_Sapma': yks_importance_df.std(),\n",
        "    'Min_Puan': yks_importance_df.min(),\n",
        "    'Max_Puan': yks_importance_df.max()\n",
        "})\n",
        "\n",
        "# Ã–nem seviyesi kategorilendirmesi\n",
        "def categorize_importance(score):\n",
        "    if score >= 9: return 'Kritik'\n",
        "    elif score >= 7: return 'YÃ¼ksek'\n",
        "    elif score >= 5: return 'Orta'\n",
        "    else: return 'DÃ¼ÅŸÃ¼k'\n",
        "\n",
        "importance_summary['Onem_Seviyesi'] = importance_summary['Ortalama_Onem_Puani'].apply(categorize_importance)\n",
        "\n",
        "print(\"ğŸ“Š YKS Ã–NEM PUANLARI TABLOSU\")\n",
        "print(\"=\" * 80)\n",
        "print(importance_summary.sort_values('Ortalama_Onem_Puani', ascending=False).head(10))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import chardet\n",
        "\n",
        "# Ã–nce dosyanÄ±n kodlamasÄ±nÄ± tespit et\n",
        "def detect_encoding(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        result = chardet.detect(f.read())\n",
        "    return result['encoding']\n",
        "\n",
        "# Dosya kodlamasÄ±nÄ± bul\n",
        "file_path = 'YKS_TYT_SORUSAYISIVERILERI.csv'\n",
        "encoding = detect_encoding(file_path)\n",
        "print(f\"Tespit edilen kodlama: {encoding}\")\n",
        "\n",
        "# FarklÄ± kodlamalarla dene\n",
        "encodings_to_try = ['utf-8', 'iso-8859-9', 'latin-1', 'windows-1254', 'cp1254']\n",
        "\n",
        "for enc in encodings_to_try:\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, sep=';', encoding=enc)\n",
        "        print(f\"âœ… BaÅŸarÄ±lÄ±: {enc}\")\n",
        "        break\n",
        "    except UnicodeDecodeError:\n",
        "        print(f\"âŒ BaÅŸarÄ±sÄ±z: {enc}\")\n",
        "        continue\n",
        "else:\n",
        "    print(\"HiÃ§bir kodlama Ã§alÄ±ÅŸmadÄ±!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfQ9K868L1GK",
        "outputId": "2765c375-d5d7-44de-a840-802ad44345a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tespit edilen kodlama: ISO-8859-1\n",
            "âŒ BaÅŸarÄ±sÄ±z: utf-8\n",
            "âœ… BaÅŸarÄ±lÄ±: iso-8859-9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 1. YKS Verileri SimÃ¼lasyonu ve YÃ¼kleme/Temizleme ModÃ¼lÃ¼ (Hata DÃ¼zeltmesi Dahil)\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "def yukle_ve_temizle(file_path):\n",
        "    \"\"\"\n",
        "    Veri dosyasÄ±nÄ± yÃ¼kler, sÃ¼tun adlarÄ±nÄ± temizler ve veri tiplerini dÃ¼zenler.\n",
        "    'UnicodeDecodeError' hatasÄ± iÃ§in 'latin-1' encoding kullanÄ±lmÄ±ÅŸtÄ±r.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # HATA DÃœZELTMESÄ°: 'latin-1' encoding'i eklenmiÅŸtir.\n",
        "        df = pd.read_csv(file_path, delimiter=';', encoding='latin-1')\n",
        "    except UnicodeDecodeError:\n",
        "        # Latin-1 iÅŸe yaramazsa cp1254'Ã¼ dene.\n",
        "        df = pd.read_csv(file_path, delimiter=';', encoding='cp1254')\n",
        "\n",
        "    # SÃ¼tun adlarÄ±nÄ± temizleme ve standardize etme\n",
        "    df.columns = df.columns.str.strip().str.replace(' ', '_').str.replace('-', '_').str.replace(':', '').str.replace('(', '').str.replace(')', '')\n",
        "\n",
        "    # TÃ¼rkÃ§e sÃ¼tun adlarÄ±nÄ± standardize etme\n",
        "    df = df.rename(columns={\n",
        "        'Ders_adi': 'Ders_AdÄ±', 'Soru_Sayisi': 'Soru_SayÄ±sÄ±', 'Dogru_Sayisi': 'DoÄŸru_SayÄ±sÄ±',\n",
        "        'Yanlis_Sayisi': 'YanlÄ±ÅŸ_SayÄ±sÄ±', 'Bos_Sayisi': 'BoÅŸ_SayÄ±sÄ±'\n",
        "    }, errors='ignore')\n",
        "\n",
        "    df['Konular'] = df['Konular'].str.strip()\n",
        "    df['Ders_AdÄ±'] = df['Ders_AdÄ±'].str.strip()\n",
        "\n",
        "    # Ä°Ã§erik Hata YÃ¶netimi: TÃ¼rkce -> TÃ¼rkÃ§e dÃ¶nÃ¼ÅŸÃ¼mÃ¼\n",
        "    df['Ders_AdÄ±'] = df['Ders_AdÄ±'].str.replace('TÃ¼rkce', 'TÃ¼rkÃ§e', regex=False).str.replace('TÃ¼rkÃ§e;', 'TÃ¼rkÃ§e', regex=False)\n",
        "\n",
        "    # SayÄ±sal sÃ¼tunlarÄ± dÃ¶nÃ¼ÅŸtÃ¼rme ve eksik veriyi 0 ile doldurma (Hata YÃ¶netimi)\n",
        "    numeric_cols = ['Soru_SayÄ±sÄ±', 'DoÄŸru_SayÄ±sÄ±', 'YanlÄ±ÅŸ_SayÄ±sÄ±', 'BoÅŸ_SayÄ±sÄ±']\n",
        "    for col in numeric_cols:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "def yks_onem_puani_simulasyonu(df):\n",
        "    \"\"\"\n",
        "    YKS Ã–nem PuanlarÄ±nÄ± ve Trend SkorlarÄ±nÄ± simÃ¼le eder.\n",
        "    NOT: Bu modÃ¼l, gÃ¼ncel YKS verileri ile yÄ±llÄ±k olarak gÃ¼ncellenmelidir.\n",
        "    \"\"\"\n",
        "    np.random.seed(42)\n",
        "    unique_topics = df['Konular'].unique()\n",
        "    subject_importance_base = {\n",
        "        'Matematik': 90, 'TÃ¼rkÃ§e': 85, 'Fizik': 70, 'Kimya': 65, 'Geometri': 75\n",
        "    }\n",
        "\n",
        "    yks_data = []\n",
        "    for topic in unique_topics:\n",
        "        topic_filter = df[df['Konular'] == topic]\n",
        "        if topic_filter.empty: continue\n",
        "        subject = topic_filter['Ders_AdÄ±'].iloc[0]\n",
        "\n",
        "        # Konu aÄŸÄ±rlÄ±klandÄ±rmasÄ± ve trend analizi\n",
        "        base_score = subject_importance_base.get(subject, 50)\n",
        "        importance_score = min(100, max(0, int(base_score + np.random.normal(0, 10))))\n",
        "        trend_score = np.random.randint(40, 95)\n",
        "\n",
        "        if importance_score >= 80: category = 'Kritik'\n",
        "        elif importance_score >= 65: category = 'YÃ¼ksek'\n",
        "        elif importance_score >= 50: category = 'Orta'\n",
        "        else: category = 'DÃ¼ÅŸÃ¼k'\n",
        "\n",
        "        avg_q_count = np.random.randint(1, 6)\n",
        "        avg_point_value = round(importance_score * 0.01 * avg_q_count * 2.5, 2)\n",
        "        frequency = np.random.randint(1, 6)\n",
        "\n",
        "        yks_data.append({\n",
        "            'Konular': topic, 'Ders_AdÄ±': subject, 'YKS_Ã–nem_PuanÄ±': importance_score,\n",
        "            'Konu_Trend_Skoru': trend_score, 'Ã–nem_Seviyesi_Kategorisi': category,\n",
        "            'Ortalama_Soru_SayÄ±sÄ±': avg_q_count, 'Ortalama_Puan_DeÄŸeri': avg_point_value,\n",
        "            'Son_5_YÄ±l_Ã‡Ä±kÄ±ÅŸ_SÄ±klÄ±ÄŸÄ±': frequency\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(yks_data)\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 2. Makine Ã–ÄŸrenmesi Modeli (Regresyon YaklaÅŸÄ±mÄ±) ve Puanlama HesaplamalarÄ±\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "def performans_ve_oncelik_hesaplama(df_merged):\n",
        "    \"\"\"Ã–ÄŸrenci Performans PuanÄ± ve Ã‡alÄ±ÅŸma Ã–ncelik Skorunu hesaplar.\"\"\"\n",
        "\n",
        "    # Puanlama Sistemi HesaplamasÄ±: (DoÄŸru * Ã–nem - YanlÄ±ÅŸ * Ã–nem - BoÅŸ * 1)\n",
        "    df_merged['Ã–ÄŸrenci_Performans_PuanÄ±'] = (\n",
        "        df_merged['DoÄŸru_SayÄ±sÄ±'] * df_merged['YKS_Ã–nem_PuanÄ±'] +\n",
        "        df_merged['YanlÄ±ÅŸ_SayÄ±sÄ±'] * df_merged['YKS_Ã–nem_PuanÄ±'] * (-1) +\n",
        "        df_merged['BoÅŸ_SayÄ±sÄ±'] * (-1)\n",
        "    )\n",
        "\n",
        "    df_merged['BaÅŸarÄ±_OranÄ±'] = df_merged['DoÄŸru_SayÄ±sÄ±'] / df_merged['Soru_SayÄ±sÄ±']\n",
        "    df_merged['BaÅŸarÄ±_OranÄ±'] = df_merged['BaÅŸarÄ±_OranÄ±'].fillna(0) # Eksik veri yÃ¶netimi\n",
        "\n",
        "    # Model FormÃ¼lÃ¼ (Ã‡alÄ±ÅŸma Ã–ncelik Skoru)\n",
        "    A = 0.7  # Performans aÃ§Ä±ÄŸÄ±na verilen aÄŸÄ±rlÄ±k\n",
        "    B = 0.3  # Trend skoruna verilen aÄŸÄ±rlÄ±k\n",
        "    df_merged['Ã‡alÄ±ÅŸma_Ã–ncelik_Skoru'] = (\n",
        "        A * df_merged['YKS_Ã–nem_PuanÄ±'] * (1 - df_merged['BaÅŸarÄ±_OranÄ±']) +\n",
        "        B * df_merged['Konu_Trend_Skoru']\n",
        "    )\n",
        "\n",
        "    # Veri Normalizasyonu ve Ã–lÃ§eklendirme (0-100)\n",
        "    scaler = MinMaxScaler(feature_range=(0, 100))\n",
        "    df_merged['Ã‡alÄ±ÅŸma_Ã–ncelik_Skoru'] = scaler.fit_transform(df_merged[['Ã‡alÄ±ÅŸma_Ã–ncelik_Skoru']])\n",
        "\n",
        "    # Konu bazlÄ± toparlanmÄ±ÅŸ analiz\n",
        "    df_analysis = df_merged.groupby(['Konular', 'Ders_AdÄ±', 'YKS_Ã–nem_PuanÄ±', 'Konu_Trend_Skoru', 'Ã–nem_Seviyesi_Kategorisi']).agg(\n",
        "        Soru_SayÄ±sÄ±=('Soru_SayÄ±sÄ±', 'sum'),\n",
        "        DoÄŸru_SayÄ±sÄ±=('DoÄŸru_SayÄ±sÄ±', 'sum'),\n",
        "        YanlÄ±ÅŸ_SayÄ±sÄ±=('YanlÄ±ÅŸ_SayÄ±sÄ±', 'sum'),\n",
        "        BoÅŸ_SayÄ±sÄ±=('BoÅŸ_SayÄ±sÄ±', 'sum'),\n",
        "        Ã–ÄŸrenci_Performans_PuanÄ±=('Ã–ÄŸrenci_Performans_PuanÄ±', 'sum'),\n",
        "        Ortalama_Ã‡alÄ±ÅŸma_Ã–ncelik_Skoru=('Ã‡alÄ±ÅŸma_Ã–ncelik_Skoru', 'mean')\n",
        "    ).reset_index()\n",
        "\n",
        "    df_analysis['BaÅŸarÄ±_OranÄ±'] = df_analysis['DoÄŸru_SayÄ±sÄ±'] / df_analysis['Soru_SayÄ±sÄ±']\n",
        "    df_analysis['BaÅŸarÄ±_OranÄ±'] = df_analysis['BaÅŸarÄ±_OranÄ±'].fillna(0)\n",
        "    df_analysis['BaÅŸarÄ±_OranÄ±_%'] = (df_analysis['BaÅŸarÄ±_OranÄ±'] * 100).round(2)\n",
        "\n",
        "    return df_analysis\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 3. Ã–neri Sistemi AlgoritmasÄ± ve Ã‡Ä±ktÄ±lar\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "def onerileri_olustur(df_analysis):\n",
        "    \"\"\"En yÃ¼ksek Ã¶ncelikli konularÄ±, gerekÃ§eleri ve tahmini geliÅŸim potansiyelini Ã¼retir.\"\"\"\n",
        "\n",
        "    df_recommendations = df_analysis.sort_values(by='Ortalama_Ã‡alÄ±ÅŸma_Ã–ncelik_Skoru', ascending=False).head(10).copy()\n",
        "\n",
        "    def get_rationale_and_potential(row):\n",
        "        rationale = []\n",
        "        importance_category = row['Ã–nem_Seviyesi_Kategorisi']\n",
        "        trend_score = row['Konu_Trend_Skoru']\n",
        "\n",
        "        # Temel Bilgiler\n",
        "        rationale.append(f\"YKS AÄŸÄ±rlÄ±ÄŸÄ±: {row['YKS_Ã–nem_PuanÄ±']} ({importance_category})\")\n",
        "        rationale.append(f\"BaÅŸarÄ± OranÄ±: %{row['BaÅŸarÄ±_OranÄ±_%']}\")\n",
        "        rationale.append(f\"Trend Skoru: {trend_score} (Trend YÃ¼ksek)\" if trend_score >= 75 else f\"Trend Skoru: {trend_score} (Trend Orta/DÃ¼ÅŸÃ¼k)\")\n",
        "\n",
        "        potential = 'Orta'\n",
        "\n",
        "        # Stratejik GerekÃ§e ve Potansiyel Belirleme KurallarÄ±\n",
        "        if importance_category in ['Kritik', 'YÃ¼ksek'] and row['BaÅŸarÄ±_OranÄ±_%'] < 70:\n",
        "            rationale.insert(0, \"YÃ¼ksek Ã–nem + DÃ¼ÅŸÃ¼k Performans (Ana Ã–ncelik)\")\n",
        "            potential = 'Ã‡ok YÃ¼ksek'\n",
        "        elif trend_score >= 75 and row['BaÅŸarÄ±_OranÄ±_%'] < 80:\n",
        "            rationale.insert(0, \"YÃ¼kselen Trend + GeliÅŸtirilebilir Performans\")\n",
        "            potential = 'YÃ¼ksek'\n",
        "        elif importance_category in ['Kritik', 'YÃ¼ksek'] and row['BaÅŸarÄ±_OranÄ±_%'] >= 85:\n",
        "            rationale.insert(0, \"YÃ¼ksek Ã–nem + YÃ¼ksek Performans (PekiÅŸtirme Ã–nerisi)\")\n",
        "            potential = 'Orta/PekiÅŸtirme'\n",
        "        elif row['BaÅŸarÄ±_OranÄ±_%'] < 50:\n",
        "            rationale.insert(0, \"Ã‡ok DÃ¼ÅŸÃ¼k Performans (Temel Eksiklik)\")\n",
        "            potential = 'YÃ¼ksek'\n",
        "        else:\n",
        "            rationale.insert(0, \"Genel Ã–ncelik Seviyesi YÃ¼ksek\")\n",
        "            potential = 'Orta'\n",
        "\n",
        "        return pd.Series([\" | \".join(rationale), potential])\n",
        "\n",
        "    df_recommendations[['GerekÃ§e', 'Tahmini_GeliÅŸim_Potansiyeli']] = df_recommendations.apply(get_rationale_and_potential, axis=1)\n",
        "\n",
        "    # SonuÃ§ sÃ¼tunlarÄ±nÄ± dÃ¼zenleme\n",
        "    final_recommendations = df_recommendations[['Ders_AdÄ±', 'Konular', 'Ortalama_Ã‡alÄ±ÅŸma_Ã–ncelik_Skoru', 'GerekÃ§e', 'Tahmini_GeliÅŸim_Potansiyeli']]\n",
        "    final_recommendations['Ortalama_Ã‡alÄ±ÅŸma_Ã–ncelik_Skoru'] = final_recommendations['Ortalama_Ã‡alÄ±ÅŸma_Ã–ncelik_Skoru'].round(2)\n",
        "\n",
        "    # Ders bazlÄ± Ã¶ncelik sÄ±ralamasÄ±nÄ± hazÄ±rlama\n",
        "    ders_bazli_oncelik = final_recommendations.sort_values(by='Ortalama_Ã‡alÄ±ÅŸma_Ã–ncelik_Skoru', ascending=False).drop_duplicates(subset=['Ders_AdÄ±'], keep='first')\n",
        "\n",
        "    return final_recommendations, ders_bazli_oncelik[['Ders_AdÄ±', 'Ortalama_Ã‡alÄ±ÅŸma_Ã–ncelik_Skoru']]\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Ana Ã‡alÄ±ÅŸma AkÄ±ÅŸÄ±\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "# Veri YÃ¼kleme ve YKS SimÃ¼lasyonu\n",
        "df_student = yukle_ve_temizle('YKS_TYT_SORUSAYISIVERILERI.csv')\n",
        "df_yks = yks_onem_puani_simulasyonu(df_student)\n",
        "\n",
        "# Veri BirleÅŸtirme (YÄ±llÄ±k GÃ¼ncelleme YapÄ±sÄ±)\n",
        "df_merged = pd.merge(df_student, df_yks, on=['Konular', 'Ders_AdÄ±'], how='left')\n",
        "\n",
        "# Hata YÃ¶netimi: YKS Ã–nem PuanÄ± NaN olan konularÄ± ortalama ile doldurma (Eksik Veri YÃ¶netimi)\n",
        "mean_importance = df_merged['YKS_Ã–nem_PuanÄ±'].mean()\n",
        "df_merged['YKS_Ã–nem_PuanÄ±'] = df_merged['YKS_Ã–nem_PuanÄ±'].fillna(mean_importance).astype(int)\n",
        "\n",
        "# Performans ve Ã–ncelik SkorlarÄ±nÄ±n HesaplanmasÄ± (Model GeliÅŸtirme)\n",
        "df_analysis_final = performans_ve_oncelik_hesaplama(df_merged)\n",
        "\n",
        "# Ã‡alÄ±ÅŸma Ã–nerilerinin Ãœretilmesi\n",
        "df_recommendations, ders_bazli_oncelik = onerileri_olustur(df_analysis_final)\n",
        "\n",
        "# Ã‡Ä±ktÄ±larÄ± CSV olarak kaydetme\n",
        "yks_output_table = df_yks[['Ders_AdÄ±', 'Konular', 'YKS_Ã–nem_PuanÄ±', 'Son_5_YÄ±l_Ã‡Ä±kÄ±ÅŸ_SÄ±klÄ±ÄŸÄ±', 'Ortalama_Soru_SayÄ±sÄ±', 'Ortalama_Puan_DeÄŸeri', 'Ã–nem_Seviyesi_Kategorisi', 'Konu_Trend_Skoru']].sort_values(by='YKS_Ã–nem_PuanÄ±', ascending=False)\n",
        "yks_output_table.to_csv('yks_Ã¶nem_puanlarÄ±_simÃ¼lasyon.csv', index=False, encoding='utf-8')\n",
        "df_recommendations.to_csv('Ã§alÄ±ÅŸma_Ã¶nerileri.csv', index=False, encoding='utf-8')\n",
        "\n",
        "# Grafik OluÅŸturma\n",
        "sns.set_style(\"whitegrid\")\n",
        "fig, axes = plt.subplots(3, 1, figsize=(12, 20))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "# 1. Konu bazlÄ± performans puanÄ± grafiÄŸi\n",
        "df_plot1 = df_analysis_final.sort_values(by='Ã–ÄŸrenci_Performans_PuanÄ±', ascending=False).head(15)\n",
        "sns.barplot(data=df_plot1, x='Ã–ÄŸrenci_Performans_PuanÄ±', y='Konular', hue='Ders_AdÄ±', dodge=False, ax=axes[0])\n",
        "axes[0].set_title('Konu BazlÄ± Ã–ÄŸrenci Performans PuanÄ± (En Ä°yi 15)', fontsize=14)\n",
        "axes[0].set_xlabel('Performans PuanÄ±', fontsize=10)\n",
        "axes[0].legend(title='Ders AdÄ±', fontsize=8)\n",
        "\n",
        "# 2. DoÄŸru/YanlÄ±ÅŸ/BoÅŸ daÄŸÄ±lÄ±m grafiÄŸi\n",
        "df_agg_counts = df_analysis_final[['DoÄŸru_SayÄ±sÄ±', 'YanlÄ±ÅŸ_SayÄ±sÄ±', 'BoÅŸ_SayÄ±sÄ±']].sum().reset_index()\n",
        "df_agg_counts.columns = ['Tip', 'SayÄ±']\n",
        "sns.barplot(data=df_agg_counts, x='Tip', y='SayÄ±', ax=axes[1], palette=['green', 'red', 'lightgray'])\n",
        "axes[1].set_title('Toplam DoÄŸru, YanlÄ±ÅŸ ve BoÅŸ SayÄ±larÄ± DaÄŸÄ±lÄ±mÄ±', fontsize=14)\n",
        "axes[1].set_xlabel('Cevap Tipi', fontsize=10)\n",
        "\n",
        "# 3. YKS Ã¶nem puanlarÄ± ile Ã¶ÄŸrenci performansÄ±nÄ±n karÅŸÄ±laÅŸtÄ±rmalÄ± analizi\n",
        "df_plot3 = df_analysis_final.sort_values(by='YKS_Ã–nem_PuanÄ±', ascending=False).head(15)\n",
        "df_plot3_melted = pd.melt(df_plot3, id_vars=['Konular', 'Ders_AdÄ±'],\n",
        "                          value_vars=['YKS_Ã–nem_PuanÄ±', 'BaÅŸarÄ±_OranÄ±_%'],\n",
        "                          var_name='Metrik', value_name='DeÄŸer')\n",
        "\n",
        "sns.barplot(data=df_plot3_melted, x='DeÄŸer', y='Konular', hue='Metrik',\n",
        "            ax=axes[2], palette=['#4c72b0', '#55a868'])\n",
        "axes[2].set_title('Konu BazlÄ± YKS Ã–nem PuanÄ± vs. Ã–ÄŸrenci BaÅŸarÄ± OranÄ± (%) (En Ã–nemli 15)', fontsize=14)\n",
        "axes[2].set_xlabel('DeÄŸer (YKS PuanÄ± 0-100 / BaÅŸarÄ± OranÄ± %)', fontsize=10)\n",
        "axes[2].legend(title='Metrik', fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('grafik_analizleri.png')\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "nU0Yfcv2PaSS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 1. YKS Verileri SimÃ¼lasyonu ve YÃ¼kleme/Temizleme ModÃ¼lÃ¼\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "def yukle_ve_temizle(file_path):\n",
        "    \"\"\"\n",
        "    Veri dosyasÄ±nÄ± yÃ¼kler (Ã¶ncelikle XLSX olarak dener), sÃ¼tun adlarÄ±nÄ± temizler ve veri tiplerini dÃ¼zenler.\n",
        "    \"\"\"\n",
        "    # 1. XLSX dosyasÄ± olarak okumayÄ± dene (ParserError'u Ã§Ã¶zmek iÃ§in)\n",
        "    try:\n",
        "        # Excel dosyasÄ±nÄ± okuma\n",
        "        df = pd.read_excel(file_path)\n",
        "    except Exception:\n",
        "        # Excel okuma baÅŸarÄ±sÄ±z olursa, tekrar CSV/latin-1 olarak dener (ilk yÃ¼klenen dosya CSV ise)\n",
        "        try:\n",
        "            df = pd.read_csv(file_path, delimiter=';', encoding='latin-1')\n",
        "        except Exception:\n",
        "            try:\n",
        "                df = pd.read_csv(file_path, delimiter=';', encoding='cp1254')\n",
        "            except FileNotFoundError:\n",
        "                 raise\n",
        "\n",
        "    # SÃ¼tun adlarÄ±nÄ± temizleme ve standardize etme\n",
        "    df.columns = df.columns.str.strip().str.replace(' ', '_').str.replace('-', '_').str.replace(':', '').str.replace('(', '').str.replace(')', '')\n",
        "    df = df.rename(columns={\n",
        "        'Ders_adi': 'Ders_AdÄ±', 'Soru_Sayisi': 'Soru_SayÄ±sÄ±', 'Dogru_Sayisi': 'DoÄŸru_SayÄ±sÄ±',\n",
        "        'Yanlis_Sayisi': 'YanlÄ±ÅŸ_SayÄ±sÄ±', 'Bos_Sayisi': 'BoÅŸ_SayÄ±sÄ±'\n",
        "    }, errors='ignore')\n",
        "\n",
        "    # Tarih SÃ¼tununu Ä°ÅŸleme (Y-m-d formatÄ±nÄ± veya d.m.Y formatÄ±nÄ± destekler)\n",
        "    df['Tarih'] = df['Tarih'].astype(str).str.strip()\n",
        "    def parse_date(date_str):\n",
        "        for fmt in ('%d.%m.%Y', '%Y-%m-%d', '%Y-%m-%d %H:%M:%S'): # Excel'den gelen varsayÄ±lan datetime formatÄ±nÄ± da ekle\n",
        "            try:\n",
        "                return pd.to_datetime(date_str, format=fmt)\n",
        "            except (ValueError, TypeError):\n",
        "                continue\n",
        "        return pd.NaT\n",
        "\n",
        "    df['Tarih'] = df['Tarih'].apply(parse_date)\n",
        "\n",
        "    df['Konular'] = df['Konular'].str.strip()\n",
        "    df['Ders_AdÄ±'] = df['Ders_AdÄ±'].str.strip()\n",
        "    # TÃ¼rkÃ§e karakter tutarsÄ±zlÄ±ÄŸÄ±nÄ± giderme\n",
        "    df['Ders_AdÄ±'] = df['Ders_AdÄ±'].str.replace('TÃ¼rkce', 'TÃ¼rkÃ§e', regex=False).str.replace('TÃ¼rkÃ§e;', 'TÃ¼rkÃ§e', regex=False)\n",
        "\n",
        "    # SayÄ±sal sÃ¼tunlarÄ± dÃ¶nÃ¼ÅŸtÃ¼rme\n",
        "    numeric_cols = ['Soru_SayÄ±sÄ±', 'DoÄŸru_SayÄ±sÄ±', 'YanlÄ±ÅŸ_SayÄ±sÄ±', 'BoÅŸ_SayÄ±sÄ±']\n",
        "    for col in numeric_cols:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "def yks_onem_puani_simulasyonu(df):\n",
        "    \"\"\"YKS Ã–nem PuanlarÄ±nÄ± ve Trend SkorlarÄ±nÄ± simÃ¼le eder.\"\"\"\n",
        "    np.random.seed(42)\n",
        "    unique_topics = df['Konular'].unique()\n",
        "    subject_importance_base = {\n",
        "        'Matematik': 90, 'TÃ¼rkÃ§e': 85, 'Fizik': 70, 'Kimya': 65, 'Geometri': 75\n",
        "    }\n",
        "\n",
        "    yks_data = []\n",
        "    for topic in unique_topics:\n",
        "        topic_filter = df[df['Konular'] == topic]\n",
        "        if topic_filter.empty: continue\n",
        "        subject = topic_filter['Ders_AdÄ±'].iloc[0] if 'Ders_AdÄ±' in topic_filter.columns and not topic_filter['Ders_AdÄ±'].empty else 'Bilinmeyen'\n",
        "\n",
        "        base_score = subject_importance_base.get(subject, 50)\n",
        "        importance_score = min(100, max(0, int(base_score + np.random.normal(0, 10))))\n",
        "        trend_score = np.random.randint(40, 95)\n",
        "\n",
        "        if importance_score >= 80: category = 'Kritik'\n",
        "        elif importance_score >= 65: category = 'YÃ¼ksek'\n",
        "        elif importance_score >= 50: category = 'Orta'\n",
        "        else: category = 'DÃ¼ÅŸÃ¼k'\n",
        "\n",
        "        avg_q_count = np.random.randint(1, 6)\n",
        "        avg_point_value = round(importance_score * 0.01 * avg_q_count * 2.5, 2)\n",
        "        frequency = np.random.randint(1, 6)\n",
        "\n",
        "        yks_data.append({\n",
        "            'Konular': topic, 'Ders_AdÄ±': subject, 'YKS_Ã–nem_PuanÄ±': importance_score,\n",
        "            'Konu_Trend_Skoru': trend_score, 'Ã–nem_Seviyesi_Kategorisi': category,\n",
        "            'Ortalama_Soru_SayÄ±sÄ±': avg_q_count, 'Ortalama_Puan_DeÄŸeri': avg_point_value,\n",
        "            'Son_5_YÄ±l_Ã‡Ä±kÄ±ÅŸ_SÄ±klÄ±ÄŸÄ±': frequency\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(yks_data)\n",
        "\n",
        "def date_analysis_and_merge(df_student, review_threshold_days=70):\n",
        "    \"\"\"Konu unutma/tekrar gereksinimi analizini yapar ve ana DataFrame ile birleÅŸtirir. EÅŸik 70 gÃ¼ndÃ¼r.\"\"\"\n",
        "\n",
        "    df_last_study = df_student.groupby('Konular')['Tarih'].max().reset_index()\n",
        "    df_last_study = df_last_study.rename(columns={'Tarih': 'Son_Ã‡alÄ±ÅŸma_Tarihi'})\n",
        "\n",
        "    today = df_last_study['Son_Ã‡alÄ±ÅŸma_Tarihi'].max()\n",
        "\n",
        "    df_last_study['GeÃ§en_GÃ¼n'] = (today - df_last_study['Son_Ã‡alÄ±ÅŸma_Tarihi']).dt.days\n",
        "\n",
        "    # Tekrar Gereksinimi Belirleme (EÅŸik 70 gÃ¼n olarak ayarlandÄ±)\n",
        "    df_last_study['Tekrar_Gereksinimi'] = np.where(\n",
        "        df_last_study['GeÃ§en_GÃ¼n'] > review_threshold_days, 'Evet', 'HayÄ±r'\n",
        "    )\n",
        "\n",
        "    # Tekrar Skoru (Unutma riskini Ã¶nceliklendirir)\n",
        "    df_last_study['Tekrar_Skoru_Ham'] = np.maximum(0, df_last_study['GeÃ§en_GÃ¼n'] - review_threshold_days)\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(0, 100))\n",
        "    df_last_study['Tekrar_Skoru'] = scaler.fit_transform(df_last_study[['Tekrar_Skoru_Ham']])\n",
        "\n",
        "    df_merged = pd.merge(df_student, df_last_study[['Konular', 'Son_Ã‡alÄ±ÅŸma_Tarihi', 'GeÃ§en_GÃ¼n', 'Tekrar_Gereksinimi', 'Tekrar_Skoru']], on='Konular', how='left')\n",
        "\n",
        "    return df_merged\n",
        "\n",
        "def performans_ve_oncelik_hesaplama(df_merged):\n",
        "    \"\"\"Ã–ÄŸrenci Performans PuanÄ± ve YENÄ° Ã‡alÄ±ÅŸma Ã–ncelik Skorunu hesaplar (Tekrar Skoru dahil).\"\"\"\n",
        "\n",
        "    # Puanlama Sistemi HesaplamasÄ±: (DoÄŸru * Ã–nem - YanlÄ±ÅŸ * Ã–nem - BoÅŸ * 1)\n",
        "    df_merged['Ã–ÄŸrenci_Performans_PuanÄ±'] = (\n",
        "        df_merged['DoÄŸru_SayÄ±sÄ±'] * df_merged['YKS_Ã–nem_PuanÄ±'] +\n",
        "        df_merged['YanlÄ±ÅŸ_SayÄ±sÄ±'] * df_merged['YKS_Ã–nem_PuanÄ±'] * (-1) +\n",
        "        df_merged['BoÅŸ_SayÄ±sÄ±'] * (-1)\n",
        "    )\n",
        "\n",
        "    df_merged['BaÅŸarÄ±_OranÄ±'] = df_merged['DoÄŸru_SayÄ±sÄ±'] / df_merged['Soru_SayÄ±sÄ±']\n",
        "    df_merged['BaÅŸarÄ±_OranÄ±'] = df_merged['BaÅŸarÄ±_OranÄ±'].fillna(0)\n",
        "\n",
        "    # YENÄ° Ã‡alÄ±ÅŸma Ã–ncelik Skoru (Model FormÃ¼lÃ¼)\n",
        "    # Ã–ncelik = 0.6 * Ã–nem * (1 - BaÅŸarÄ±) + 0.3 * Trend + 0.1 * Tekrar\n",
        "    A = 0.6\n",
        "    B = 0.3\n",
        "    C = 0.1\n",
        "\n",
        "    df_merged['YKS_Ã–nem_PuanÄ±'] = df_merged['YKS_Ã–nem_PuanÄ±'].fillna(0)\n",
        "    df_merged['Konu_Trend_Skoru'] = df_merged['Konu_Trend_Skoru'].fillna(0)\n",
        "    df_merged['Tekrar_Skoru'] = df_merged['Tekrar_Skoru'].fillna(0)\n",
        "\n",
        "    df_merged['Ã‡alÄ±ÅŸma_Ã–ncelik_Skoru_Ham'] = (\n",
        "        A * df_merged['YKS_Ã–nem_PuanÄ±'] * (1 - df_merged['BaÅŸarÄ±_OranÄ±']) +\n",
        "        B * df_merged['Konu_Trend_Skoru'] +\n",
        "        C * df_merged['Tekrar_Skoru']\n",
        "    )\n",
        "\n",
        "    # Genel Normalizasyon (0-100)\n",
        "    scaler = MinMaxScaler(feature_range=(0, 100))\n",
        "    df_merged['Ã‡alÄ±ÅŸma_Ã–ncelik_Skoru'] = scaler.fit_transform(df_merged[['Ã‡alÄ±ÅŸma_Ã–ncelik_Skoru_Ham']])\n",
        "\n",
        "    # Konu bazlÄ± toparlanmÄ±ÅŸ analiz\n",
        "    df_analysis = df_merged.groupby(['Konular', 'Ders_AdÄ±', 'YKS_Ã–nem_PuanÄ±', 'Konu_Trend_Skoru', 'Ã–nem_Seviyesi_Kategorisi']).agg(\n",
        "        Soru_SayÄ±sÄ±=('Soru_SayÄ±sÄ±', 'sum'),\n",
        "        DoÄŸru_SayÄ±sÄ±=('DoÄŸru_SayÄ±sÄ±', 'sum'),\n",
        "        YanlÄ±ÅŸ_SayÄ±sÄ±=('YanlÄ±ÅŸ_SayÄ±sÄ±', 'sum'),\n",
        "        BoÅŸ_SayÄ±sÄ±=('BoÅŸ_SayÄ±sÄ±', 'sum'),\n",
        "        Ã–ÄŸrenci_Performans_PuanÄ±=('Ã–ÄŸrenci_Performans_PuanÄ±', 'sum'),\n",
        "        Ortalama_Ã‡alÄ±ÅŸma_Ã–ncelik_Skoru=('Ã‡alÄ±ÅŸma_Ã–ncelik_Skoru', 'mean'),\n",
        "        GeÃ§en_GÃ¼n=('GeÃ§en_GÃ¼n', 'min'),\n",
        "        Tekrar_Gereksinimi=('Tekrar_Gereksinimi', 'first'),\n",
        "        Tekrar_Skoru=('Tekrar_Skoru', 'mean')\n",
        "    ).reset_index()\n",
        "\n",
        "    df_analysis['BaÅŸarÄ±_OranÄ±'] = df_analysis['DoÄŸru_SayÄ±sÄ±'] / df_analysis['Soru_SayÄ±sÄ±']\n",
        "    df_analysis['BaÅŸarÄ±_OranÄ±'] = df_analysis['BaÅŸarÄ±_OranÄ±'].fillna(0)\n",
        "    df_analysis['BaÅŸarÄ±_OranÄ±_%'] = (df_analysis['BaÅŸarÄ±_OranÄ±'] * 100).round(2)\n",
        "\n",
        "    return df_analysis\n",
        "\n",
        "def generate_subject_charts(df_analysis):\n",
        "    \"\"\"Her ders iÃ§in ayrÄ± ayrÄ± YKS Ã–nem PuanÄ± vs. Ã–ÄŸrenci BaÅŸarÄ± OranÄ± (%) grafiÄŸi oluÅŸturur.\"\"\"\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    df_analysis['Ders_AdÄ±'] = df_analysis['Ders_AdÄ±'].astype(str).str.replace('TÃƒÂ¼rkÃƒÂ§e', 'TÃ¼rkÃ§e', regex=False).str.replace('TÃƒÂ¼rkce', 'TÃ¼rkÃ§e', regex=False)\n",
        "\n",
        "    unique_subjects = df_analysis['Ders_AdÄ±'].dropna().unique()\n",
        "\n",
        "    generated_files = []\n",
        "\n",
        "    for subject in unique_subjects:\n",
        "        df_subject = df_analysis[df_analysis['Ders_AdÄ±'] == subject].copy()\n",
        "        df_subject = df_subject[df_subject['Soru_SayÄ±sÄ±'] > 0]\n",
        "\n",
        "        if df_subject.empty: continue\n",
        "\n",
        "        df_subject_sorted = df_subject.sort_values(by='Ortalama_Ã‡alÄ±ÅŸma_Ã–ncelik_Skoru', ascending=False)\n",
        "\n",
        "        df_plot_melted = pd.melt(df_subject_sorted, id_vars=['Konular', 'Ã–nem_Seviyesi_Kategorisi'],\n",
        "                                  value_vars=['YKS_Ã–nem_PuanÄ±', 'BaÅŸarÄ±_OranÄ±_%'],\n",
        "                                  var_name='Metrik', value_name='DeÄŸer')\n",
        "\n",
        "        plt.figure(figsize=(10, max(5, 0.5 * len(df_subject_sorted))))\n",
        "\n",
        "        ax = sns.barplot(data=df_plot_melted, x='DeÄŸer', y='Konular', hue='Metrik',\n",
        "                         palette={'YKS_Ã–nem_PuanÄ±': '#4c72b0', 'BaÅŸarÄ±_OranÄ±_%': '#55a868'},\n",
        "                         dodge=True)\n",
        "\n",
        "        ax.set_title(f'{subject} Konu Analizi: Ã–nem vs. BaÅŸarÄ± (Ã–nceliÄŸe GÃ¶re SÄ±ralÄ±)', fontsize=14)\n",
        "        ax.set_xlabel('DeÄŸer (YKS PuanÄ± 0-100 / BaÅŸarÄ± OranÄ± %)', fontsize=10)\n",
        "        ax.set_ylabel('Konular', fontsize=10)\n",
        "        ax.legend(title='Metrik', fontsize=8, loc='lower right')\n",
        "\n",
        "        # Tekrar Gereksinimini Etikete Ekle\n",
        "        for i, row in df_subject_sorted.reset_index(drop=True).iterrows():\n",
        "            if row['Tekrar_Gereksinimi'] == 'Evet':\n",
        "                ax.text(101, i, f\"({row['GeÃ§en_GÃ¼n']} gÃ¼n Ã¶nce) âš ï¸ TEKRAR GEREKLÄ°\", color='red', va='center', fontsize=7)\n",
        "\n",
        "        plt.xlim(0, 105) # Etiketi sÄ±ÄŸdÄ±rmak iÃ§in x limitini geniÅŸlet\n",
        "        plt.tight_layout()\n",
        "\n",
        "        safe_subject_name = \"\".join(c for c in subject if c.isalnum()).lower()\n",
        "        filename = f\"{safe_subject_name}_analiz_grafigi.png\"\n",
        "        plt.savefig(filename)\n",
        "        plt.close()\n",
        "        generated_files.append(filename)\n",
        "\n",
        "    return generated_files\n",
        "\n",
        "def onerileri_olustur(df_analysis):\n",
        "    \"\"\"En yÃ¼ksek Ã¶ncelikli konularÄ±, gerekÃ§eleri ve tahmini geliÅŸim potansiyelini Ã¼retir.\"\"\"\n",
        "\n",
        "    df_recommendations = df_analysis.sort_values(by='Ortalama_Ã‡alÄ±ÅŸma_Ã–ncelik_Skoru', ascending=False).head(10).copy()\n",
        "\n",
        "    def get_rationale_and_potential(row):\n",
        "        rationale = []\n",
        "        importance_category = row['Ã–nem_Seviyesi_Kategorisi']\n",
        "        trend_score = row['Konu_Trend_Skoru']\n",
        "        tekrar_gereksinimi = row['Tekrar_Gereksinimi']\n",
        "        gecen_gun = row['GeÃ§en_GÃ¼n']\n",
        "\n",
        "        # Temel Bilgiler\n",
        "        rationale.append(f\"YKS AÄŸÄ±rlÄ±ÄŸÄ±: {row['YKS_Ã–nem_PuanÄ±']} ({importance_category})\")\n",
        "        rationale.append(f\"BaÅŸarÄ± OranÄ±: %{row['BaÅŸarÄ±_OranÄ±_%']}\")\n",
        "\n",
        "        # Tekrar Gereksinimi GerekÃ§eye Ekle\n",
        "        if tekrar_gereksinimi == 'Evet':\n",
        "            rationale.insert(0, f\"âš ï¸ TEKRAR GEREKLÄ° ({gecen_gun} gÃ¼n geÃ§ti)\")\n",
        "\n",
        "        # Stratejik GerekÃ§e ve Potansiyel Belirleme KurallarÄ±\n",
        "        potential = 'Orta' # VarsayÄ±lan deÄŸer\n",
        "\n",
        "        if importance_category in ['Kritik', 'YÃ¼ksek'] and row['BaÅŸarÄ±_OranÄ±_%'] < 70:\n",
        "            rationale.insert(0, \"YÃ¼ksek Ã–nem + DÃ¼ÅŸÃ¼k Performans (ANA Ã–NCELÄ°K)\")\n",
        "            potential = 'Ã‡ok YÃ¼ksek'\n",
        "        elif tekrar_gereksinimi == 'Evet' and importance_category in ['Kritik', 'YÃ¼ksek']:\n",
        "            rationale.insert(0, \"YÃ¼ksek Ã–nem + Unutma Riski (ACÄ°L TEKRAR)\")\n",
        "            potential = 'YÃ¼ksek'\n",
        "        elif row['BaÅŸarÄ±_OranÄ±_%'] >= 85 and tekrar_gereksinimi == 'Evet':\n",
        "             rationale.insert(0, \"YÃ¼ksek Performans + Unutma Riski (HIZLI PEKÄ°ÅTÄ°RME)\")\n",
        "             potential = 'Orta/PekiÅŸtirme'\n",
        "        elif trend_score >= 75 and row['BaÅŸarÄ±_OranÄ±_%'] < 80:\n",
        "             rationale.insert(0, \"YÃ¼kselen Trend + GeliÅŸtirilebilir Performans\")\n",
        "             potential = 'YÃ¼ksek'\n",
        "        else:\n",
        "             rationale.insert(0, \"Genel Ã–ncelik Seviyesi YÃ¼ksek\")\n",
        "\n",
        "        return pd.Series([\" | \".join(rationale), potential])\n",
        "\n",
        "    df_recommendations[['GerekÃ§e', 'Tahmini_GeliÅŸim_Potansiyeli']] = df_recommendations.apply(get_rationale_and_potential, axis=1)\n",
        "\n",
        "    final_recommendations = df_recommendations[['Ders_AdÄ±', 'Konular', 'Ortalama_Ã‡alÄ±ÅŸma_Ã–ncelik_Skoru', 'GerekÃ§e', 'Tahmini_GeliÅŸim_Potansiyeli']]\n",
        "    final_recommendations['Ortalama_Ã‡alÄ±ÅŸma_Ã–ncelik_Skoru'] = final_recommendations['Ortalama_Ã‡alÄ±ÅŸma_Ã–ncelik_Skoru'].round(2)\n",
        "\n",
        "    ders_bazli_oncelik = final_recommendations.sort_values(by='Ortalama_Ã‡alÄ±ÅŸma_Ã–ncelik_Skoru', ascending=False).drop_duplicates(subset=['Ders_AdÄ±'], keep='first')\n",
        "\n",
        "    return final_recommendations, ders_bazli_oncelik[['Ders_AdÄ±', 'Ortalama_Ã‡alÄ±ÅŸma_Ã–ncelik_Skoru']]\n",
        "\n",
        "# --- Ana Ã‡alÄ±ÅŸma AkÄ±ÅŸÄ± ---\n",
        "# 1. Veri YÃ¼kleme ve YKS SimÃ¼lasyonu\n",
        "df_student = yukle_ve_temizle('YKS_TYT_SORUSAYISIVERILERI.csv.xlsx')\n",
        "\n",
        "# NaN Tarihleri olan satÄ±rlarÄ± at (Unutma analizi iÃ§in Tarih gereklidir)\n",
        "df_student_valid_dates = df_student.dropna(subset=['Tarih'])\n",
        "\n",
        "df_yks = yks_onem_puani_simulasyonu(df_student_valid_dates)\n",
        "\n",
        "# 1.5. Yeni: Tarih BazlÄ± Unutma Analizi (EÅŸik 70 gÃ¼n olarak ayarlandÄ±)\n",
        "df_student_with_dates = date_analysis_and_merge(df_student_valid_dates, review_threshold_days=70)\n",
        "\n",
        "# 2. YKS Verilerini Ã–ÄŸrenci Verileriyle BirleÅŸtirme\n",
        "df_merged = pd.merge(df_student_with_dates, df_yks, on=['Konular', 'Ders_AdÄ±'], how='left')\n",
        "mean_importance = df_merged['YKS_Ã–nem_PuanÄ±'].mean()\n",
        "df_merged['YKS_Ã–nem_PuanÄ±'] = df_merged['YKS_Ã–nem_PuanÄ±'].fillna(mean_importance).astype(int)\n",
        "\n",
        "# 3. Performans ve Ã–ncelik SkorlarÄ±nÄ±n HesaplanmasÄ± (Tekrar Skoru dahil)\n",
        "df_analysis_final = performans_ve_oncelik_hesaplama(df_merged)\n",
        "\n",
        "# 4. Ders bazlÄ± grafiklerin oluÅŸturulmasÄ±\n",
        "generated_charts = generate_subject_charts(df_analysis_final)\n",
        "\n",
        "# 5. Ã‡alÄ±ÅŸma Ã–nerilerinin Ãœretilmesi\n",
        "df_recommendations, ders_bazli_oncelik = onerileri_olustur(df_analysis_final)\n",
        "\n",
        "# Ã‡Ä±ktÄ±larÄ± CSV olarak kaydetme\n",
        "yks_output_table = df_yks[['Ders_AdÄ±', 'Konular', 'YKS_Ã–nem_PuanÄ±', 'Son_5_YÄ±l_Ã‡Ä±kÄ±ÅŸ_SÄ±klÄ±ÄŸÄ±', 'Ortalama_Soru_SayÄ±sÄ±', 'Ortalama_Puan_DeÄŸeri', 'Ã–nem_Seviyesi_Kategorisi', 'Konu_Trend_Skoru']].sort_values(by='YKS_Ã–nem_PuanÄ±', ascending=False)\n",
        "yks_output_table.to_csv('yks_Ã¶nem_puanlarÄ±_simÃ¼lasyon.csv', index=False, encoding='utf-8')\n",
        "df_recommendations.to_csv('Ã§alÄ±ÅŸma_Ã¶nerileri.csv', index=False, encoding='utf-8')"
      ],
      "metadata": {
        "id": "RdkSg6vSVuZM"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}